{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stitch 2 pointclouds together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import teaserpp_python\n",
    "import numpy as np \n",
    "import copy\n",
    "from helpers import *\n",
    "\n",
    "VOXEL_SIZE = 0.05\n",
    "VISUALIZE = True\n",
    "\n",
    "# Load and visualize two point clouds from 3DMatch dataset\n",
    "A_pcd_raw = o3d.io.read_point_cloud('/home/szz/Documents/localizer_blueprint/examples/teaser_python_fpfh_icp/data/office_test.pcd')\n",
    "B_pcd_raw = o3d.io.read_point_cloud('/home/szz/Downloads/test.pcd')\n",
    "A_pcd_raw.paint_uniform_color([0.0, 0.0, 1.0]) # show A_pcd in blue\n",
    "B_pcd_raw.paint_uniform_color([1.0, 0.0, 0.0]) # show B_pcd in red\n",
    "if VISUALIZE:\n",
    "    o3d.visualization.draw_geometries([A_pcd_raw,B_pcd_raw]) # plot A and B \n",
    "\n",
    "# voxel downsample both clouds\n",
    "A_pcd = A_pcd_raw.voxel_down_sample(voxel_size=VOXEL_SIZE)\n",
    "B_pcd = B_pcd_raw.voxel_down_sample(voxel_size=VOXEL_SIZE)\n",
    "if VISUALIZE:\n",
    "    o3d.visualization.draw_geometries([A_pcd,B_pcd]) # plot downsampled A and B \n",
    "\n",
    "A_xyz = pcd2xyz(A_pcd) # np array of size 3 by N\n",
    "B_xyz = pcd2xyz(B_pcd) # np array of size 3 by M\n",
    "\n",
    "# extract FPFH features\n",
    "A_feats = extract_fpfh(A_pcd,VOXEL_SIZE)\n",
    "B_feats = extract_fpfh(B_pcd,VOXEL_SIZE)\n",
    "\n",
    "# establish correspondences by nearest neighbour search in feature space\n",
    "corrs_A, corrs_B = find_correspondences(\n",
    "    A_feats, B_feats, mutual_filter=True)\n",
    "A_corr = A_xyz[:,corrs_A] # np array of size 3 by num_corrs\n",
    "B_corr = B_xyz[:,corrs_B] # np array of size 3 by num_corrs\n",
    "\n",
    "num_corrs = A_corr.shape[1]\n",
    "print(f'FPFH generates {num_corrs} putative correspondences.')\n",
    "\n",
    "# visualize the point clouds together with feature correspondences\n",
    "points = np.concatenate((A_corr.T,B_corr.T),axis=0)\n",
    "lines = []\n",
    "for i in range(num_corrs):\n",
    "    lines.append([i,i+num_corrs])\n",
    "colors = [[0, 1, 0] for i in range(len(lines))] # lines are shown in green\n",
    "line_set = o3d.geometry.LineSet(\n",
    "    points=o3d.utility.Vector3dVector(points),\n",
    "    lines=o3d.utility.Vector2iVector(lines),\n",
    ")\n",
    "line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "o3d.visualization.draw_geometries([A_pcd,B_pcd,line_set])\n",
    "\n",
    "# robust global registration using TEASER++\n",
    "NOISE_BOUND = VOXEL_SIZE\n",
    "teaser_solver = get_teaser_solver(NOISE_BOUND)\n",
    "teaser_solver.solve(A_corr,B_corr)\n",
    "solution = teaser_solver.getSolution()\n",
    "R_teaser = solution.rotation\n",
    "t_teaser = solution.translation\n",
    "T_teaser = Rt2T(R_teaser,t_teaser)\n",
    "\n",
    "# Visualize the registration results\n",
    "A_pcd_T_teaser = copy.deepcopy(A_pcd).transform(T_teaser)\n",
    "o3d.visualization.draw_geometries([A_pcd_T_teaser,B_pcd])\n",
    "\n",
    "# local refinement using ICP\n",
    "icp_sol = o3d.pipelines.registration.registration_icp(\n",
    "      A_pcd, B_pcd, NOISE_BOUND, T_teaser,\n",
    "      o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "      o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=100))\n",
    "T_icp = icp_sol.transformation\n",
    "\n",
    "print (T_icp)\n",
    "\n",
    "# visualize the registration after ICP refinement\n",
    "A_pcd_T_icp = copy.deepcopy(A_pcd).transform(T_icp)\n",
    "o3d.visualization.draw_geometries([A_pcd_T_icp,B_pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stitch multiple pointclouds together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import teaserpp_python\n",
    "import numpy as np\n",
    "import copy\n",
    "from helpers import *\n",
    "\n",
    "VOXEL_SIZE = 0.02\n",
    "VISUALIZE = True\n",
    "\n",
    "def process_point_clouds(A_pcd_raw, B_pcd_raw, voxel_size):\n",
    " try:\n",
    " # voxel downsample both clouds\n",
    " A_pcd = A_pcd_raw.voxel_down_sample(voxel_size=voxel_size)\n",
    " B_pcd = B_pcd_raw.voxel_down_sample(voxel_size=voxel_size)\n",
    " if VISUALIZE:\n",
    " o3d.visualization.draw_geometries([A_pcd, B_pcd]) # plot downsampled A and B\n",
    "\n",
    " A_xyz = pcd2xyz(A_pcd) # np array of size 3 by N\n",
    " B_xyz = pcd2xyz(B_pcd) # np array of size 3 by M\n",
    "\n",
    " # extract FPFH features\n",
    " A_feats = extract_fpfh(A_pcd, voxel_size)\n",
    " B_feats = extract_fpfh(B_pcd, voxel_size)\n",
    "\n",
    " # establish correspondences by nearest neighbour search in feature space\n",
    " corrs_A, corrs_B = find_correspondences(A_feats, B_feats, mutual_filter=True)\n",
    " A_corr = A_xyz[:, corrs_A] # np array of size 3 by num_corrs\n",
    " B_corr = B_xyz[:, corrs_B] # np array of size 3 by num_corrs\n",
    "\n",
    " num_corrs = A_corr.shape[1]\n",
    " print(f'FPFH generates {num_corrs} putative correspondences.')\n",
    "\n",
    " # visualize the point clouds together with feature correspondences\n",
    " points = np.concatenate((A_corr.T, B_corr.T), axis=0)\n",
    " lines = [[i, i + num_corrs] for i in range(num_corrs)]\n",
    " colors = [[0, 1, 0] for _ in range(len(lines))] # lines are shown in green\n",
    " line_set = o3d.geometry.LineSet(\n",
    " points=o3d.utility.Vector3dVector(points),\n",
    " lines=o3d.utility.Vector2iVector(lines),\n",
    " )\n",
    " line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    " o3d.visualization.draw_geometries([A_pcd, B_pcd, line_set])\n",
    "\n",
    " # robust global registration using TEASER++\n",
    " NOISE_BOUND = voxel_size\n",
    " teaser_solver = get_teaser_solver(NOISE_BOUND)\n",
    " teaser_solver.solve(A_corr, B_corr)\n",
    " solution = teaser_solver.getSolution()\n",
    " R_teaser = solution.rotation\n",
    " t_teaser = solution.translation\n",
    " T_teaser = Rt2T(R_teaser, t_teaser)\n",
    "\n",
    " # Visualize the registration results\n",
    " A_pcd_T_teaser = copy.deepcopy(A_pcd).transform(T_teaser)\n",
    " o3d.visualization.draw_geometries([A_pcd_T_teaser, B_pcd])\n",
    "\n",
    " # local refinement using ICP\n",
    " icp_sol = o3d.pipelines.registration.registration_icp(\n",
    " A_pcd, B_pcd, NOISE_BOUND, T_teaser,\n",
    " o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    " o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=100))\n",
    " T_icp = icp_sol.transformation\n",
    "\n",
    " # visualize the registration after ICP refinement\n",
    " A_pcd_T_icp = copy.deepcopy(A_pcd).transform(T_icp)\n",
    " o3d.visualization.draw_geometries([A_pcd_T_icp, B_pcd])\n",
    "\n",
    " # Combine the two point clouds into one\n",
    " A_points = np.asarray(A_pcd_T_icp.points)\n",
    " B_points = np.asarray(B_pcd.points)\n",
    "\n",
    " # Merge the points and colors (if any)\n",
    " merged_points = np.vstack((A_points, B_points))\n",
    "\n",
    " # Create a new point cloud with the merged points\n",
    " merged_pcd = o3d.geometry.PointCloud()\n",
    " merged_pcd.points = o3d.utility.Vector3dVector(merged_points)\n",
    "\n",
    " # Optionally, you can also merge the colors if you want to preserve them\n",
    " if A_pcd_T_icp.has_colors() and B_pcd.has_colors():\n",
    " A_colors = np.asarray(A_pcd_T_icp.colors)\n",
    " B_colors = np.asarray(B_pcd.colors)\n",
    " merged_colors = np.vstack((A_colors, B_colors))\n",
    " merged_pcd.colors = o3d.utility.Vector3dVector(merged_colors)\n",
    "\n",
    " return merged_pcd\n",
    " except Exception as e:\n",
    " print(f\"Error processing point clouds: {e}\")\n",
    " return None\n",
    "\n",
    "def read_point_cloud(file_or_pcd):\n",
    " if isinstance(file_or_pcd, str):\n",
    " return o3d.io.read_point_cloud(file_or_pcd)\n",
    " elif isinstance(file_or_pcd, o3d.geometry.PointCloud):\n",
    " return file_or_pcd\n",
    " else:\n",
    " raise TypeError(\"Input must be a file path or a PointCloud object\")\n",
    "\n",
    "def merge_pairwise(pcd_list, voxel_size):\n",
    " # Merge point clouds in pairs\n",
    " merged_pcd_list = []\n",
    " for i in range(0, len(pcd_list), 2):\n",
    " if i + 1 < len(pcd_list):\n",
    " pcd1 = read_point_cloud(pcd_list[i])\n",
    " pcd2 = read_point_cloud(pcd_list[i + 1])\n",
    " merged_pcd = process_point_clouds(pcd1, pcd2, voxel_size)\n",
    " merged_pcd_list.append(merged_pcd)\n",
    " else:\n",
    " # If there is an odd number of point clouds, add the last one directly\n",
    " pcd = read_point_cloud(pcd_list[i])\n",
    " merged_pcd_list.append(pcd)\n",
    " return merged_pcd_list\n",
    "\n",
    "def merge_multiple_point_clouds(pcd_paths, voxel_size):\n",
    " while len(pcd_paths) > 1:\n",
    " pcd_paths = merge_pairwise(pcd_paths, voxel_size)\n",
    " return pcd_paths[0] if pcd_paths else None\n",
    "\n",
    "# List of point cloud files to merge\n",
    "pcd_files = ['back_side_front.pcd','back_side_left.pcd', 'helmet_top.ply', 'back_side_right.pcd']\n",
    "\n",
    "# Merge all point clouds\n",
    "final_merged_pcd = merge_multiple_point_clouds(pcd_files, VOXEL_SIZE)\n",
    "\n",
    "# Save the final merged point cloud\n",
    "if final_merged_pcd:\n",
    " o3d.io.write_point_cloud(\"final_merged.ply\", final_merged_pcd)\n",
    "else:\n",
    " print(\"Merging failed.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
